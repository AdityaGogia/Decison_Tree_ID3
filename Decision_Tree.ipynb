{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eeaf291a",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "7cfea447",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from tkinter import filedialog as fd\n",
    "import time\n",
    "import tracemalloc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c70f29",
   "metadata": {},
   "source": [
    "# Take the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "795bfc9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Attribute is:  10\n"
     ]
    }
   ],
   "source": [
    "filename = fd.askopenfilename()\n",
    "df = pd.read_csv(filename, header=None,skiprows=1)\n",
    "df.head(10)\n",
    "last_col = df.keys()[-1]\n",
    "print('Target Attribute is: ', last_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1b807c",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d97b1d",
   "metadata": {},
   "source": [
    "### Missing values imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "0022b161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1.51761</td>\n",
       "      <td>13.89</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1.51618</td>\n",
       "      <td>13.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1.51766</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1.51742</td>\n",
       "      <td>13.27</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.24</td>\n",
       "      <td>73.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>1.51596</td>\n",
       "      <td>12.79</td>\n",
       "      <td>3.61</td>\n",
       "      <td>1.62</td>\n",
       "      <td>72.97</td>\n",
       "      <td>0.64</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>210</td>\n",
       "      <td>1.51623</td>\n",
       "      <td>14.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.88</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.08</td>\n",
       "      <td>9.18</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>211</td>\n",
       "      <td>1.51685</td>\n",
       "      <td>14.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.99</td>\n",
       "      <td>73.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.40</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>212</td>\n",
       "      <td>1.52065</td>\n",
       "      <td>14.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.02</td>\n",
       "      <td>73.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.44</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>213</td>\n",
       "      <td>1.51651</td>\n",
       "      <td>14.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.94</td>\n",
       "      <td>73.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.48</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>214</td>\n",
       "      <td>1.51711</td>\n",
       "      <td>14.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.08</td>\n",
       "      <td>73.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.62</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>213 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0        1      2     3     4      5     6     7     8     9   10\n",
       "0      2  1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.00  0.00   1\n",
       "1      3  1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.00  0.00   1\n",
       "2      4  1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.00  0.00   1\n",
       "3      5  1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.00  0.00   1\n",
       "4      6  1.51596  12.79  3.61  1.62  72.97  0.64  8.07  0.00  0.26   1\n",
       "..   ...      ...    ...   ...   ...    ...   ...   ...   ...   ...  ..\n",
       "208  210  1.51623  14.14  0.00  2.88  72.61  0.08  9.18  1.06  0.00   7\n",
       "209  211  1.51685  14.92  0.00  1.99  73.06  0.00  8.40  1.59  0.00   7\n",
       "210  212  1.52065  14.36  0.00  2.02  73.42  0.00  8.44  1.64  0.00   7\n",
       "211  213  1.51651  14.38  0.00  1.94  73.61  0.00  8.48  1.57  0.00   7\n",
       "212  214  1.51711  14.23  0.00  2.08  73.36  0.00  8.62  1.67  0.00   7\n",
       "\n",
       "[213 rows x 11 columns]"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "fca06112",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df=df.fillna(df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "ead9078d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1.51761</td>\n",
       "      <td>13.89</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1.51618</td>\n",
       "      <td>13.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1.51766</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1.51742</td>\n",
       "      <td>13.27</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.24</td>\n",
       "      <td>73.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>1.51596</td>\n",
       "      <td>12.79</td>\n",
       "      <td>3.61</td>\n",
       "      <td>1.62</td>\n",
       "      <td>72.97</td>\n",
       "      <td>0.64</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>210</td>\n",
       "      <td>1.51623</td>\n",
       "      <td>14.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.88</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.08</td>\n",
       "      <td>9.18</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>211</td>\n",
       "      <td>1.51685</td>\n",
       "      <td>14.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.99</td>\n",
       "      <td>73.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.40</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>212</td>\n",
       "      <td>1.52065</td>\n",
       "      <td>14.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.02</td>\n",
       "      <td>73.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.44</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>213</td>\n",
       "      <td>1.51651</td>\n",
       "      <td>14.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.94</td>\n",
       "      <td>73.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.48</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>214</td>\n",
       "      <td>1.51711</td>\n",
       "      <td>14.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.08</td>\n",
       "      <td>73.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.62</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>213 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0        1      2     3     4      5     6     7     8     9   10\n",
       "0      2  1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.00  0.00   1\n",
       "1      3  1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.00  0.00   1\n",
       "2      4  1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.00  0.00   1\n",
       "3      5  1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.00  0.00   1\n",
       "4      6  1.51596  12.79  3.61  1.62  72.97  0.64  8.07  0.00  0.26   1\n",
       "..   ...      ...    ...   ...   ...    ...   ...   ...   ...   ...  ..\n",
       "208  210  1.51623  14.14  0.00  2.88  72.61  0.08  9.18  1.06  0.00   7\n",
       "209  211  1.51685  14.92  0.00  1.99  73.06  0.00  8.40  1.59  0.00   7\n",
       "210  212  1.52065  14.36  0.00  2.02  73.42  0.00  8.44  1.64  0.00   7\n",
       "211  213  1.51651  14.38  0.00  1.94  73.61  0.00  8.48  1.57  0.00   7\n",
       "212  214  1.51711  14.23  0.00  2.08  73.36  0.00  8.62  1.67  0.00   7\n",
       "\n",
       "[213 rows x 11 columns]"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161a6037",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "ed7aa303",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>213.000000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>213.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>108.000000</td>\n",
       "      <td>1.518353</td>\n",
       "      <td>13.406761</td>\n",
       "      <td>2.676056</td>\n",
       "      <td>1.446526</td>\n",
       "      <td>72.655023</td>\n",
       "      <td>0.499108</td>\n",
       "      <td>8.957934</td>\n",
       "      <td>0.175869</td>\n",
       "      <td>0.057277</td>\n",
       "      <td>2.788732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>61.631972</td>\n",
       "      <td>0.003039</td>\n",
       "      <td>0.818371</td>\n",
       "      <td>1.440453</td>\n",
       "      <td>0.499882</td>\n",
       "      <td>0.774052</td>\n",
       "      <td>0.653035</td>\n",
       "      <td>1.426435</td>\n",
       "      <td>0.498245</td>\n",
       "      <td>0.097589</td>\n",
       "      <td>2.105130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.511150</td>\n",
       "      <td>10.730000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>69.810000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.430000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.516520</td>\n",
       "      <td>12.900000</td>\n",
       "      <td>2.090000</td>\n",
       "      <td>1.190000</td>\n",
       "      <td>72.280000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>8.240000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>108.000000</td>\n",
       "      <td>1.517680</td>\n",
       "      <td>13.300000</td>\n",
       "      <td>3.480000</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>72.790000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>161.000000</td>\n",
       "      <td>1.519150</td>\n",
       "      <td>13.830000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>1.630000</td>\n",
       "      <td>73.090000</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>9.180000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>214.000000</td>\n",
       "      <td>1.533930</td>\n",
       "      <td>17.380000</td>\n",
       "      <td>3.980000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>75.410000</td>\n",
       "      <td>6.210000</td>\n",
       "      <td>16.190000</td>\n",
       "      <td>3.150000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  213.000000  213.000000  213.000000  213.000000  213.000000  213.000000   \n",
       "mean   108.000000    1.518353   13.406761    2.676056    1.446526   72.655023   \n",
       "std     61.631972    0.003039    0.818371    1.440453    0.499882    0.774052   \n",
       "min      2.000000    1.511150   10.730000    0.000000    0.290000   69.810000   \n",
       "25%     55.000000    1.516520   12.900000    2.090000    1.190000   72.280000   \n",
       "50%    108.000000    1.517680   13.300000    3.480000    1.360000   72.790000   \n",
       "75%    161.000000    1.519150   13.830000    3.600000    1.630000   73.090000   \n",
       "max    214.000000    1.533930   17.380000    3.980000    3.500000   75.410000   \n",
       "\n",
       "               6           7           8           9           10  \n",
       "count  213.000000  213.000000  213.000000  213.000000  213.000000  \n",
       "mean     0.499108    8.957934    0.175869    0.057277    2.788732  \n",
       "std      0.653035    1.426435    0.498245    0.097589    2.105130  \n",
       "min      0.000000    5.430000    0.000000    0.000000    1.000000  \n",
       "25%      0.130000    8.240000    0.000000    0.000000    1.000000  \n",
       "50%      0.560000    8.600000    0.000000    0.000000    2.000000  \n",
       "75%      0.610000    9.180000    0.000000    0.100000    3.000000  \n",
       "max      6.210000   16.190000    3.150000    0.510000    7.000000  "
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8980ed20",
   "metadata": {},
   "source": [
    "### Creating a correlation matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "9400bf48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "correlationMatrix=df.corr()\n",
    "dataplot=sns.heatmap(correlationMatrix)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ed5ae5",
   "metadata": {},
   "source": [
    "### Identifying highly correlated features in the dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "e7c36bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\villu\\AppData\\Local\\Temp\\ipykernel_46716\\1327407657.py:1: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  upper = correlationMatrix.where(np.triu(np.ones(correlationMatrix.shape), k=1).astype(np.bool))\n"
     ]
    }
   ],
   "source": [
    "upper = correlationMatrix.where(np.triu(np.ones(correlationMatrix.shape), k=1).astype(np.bool))\n",
    "# Find the feature column index with a correlation greater than 0.95.\n",
    "colToDrop = [column for column in upper.columns if any(upper[column] > 0.95)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748d70ae",
   "metadata": {},
   "source": [
    "### Dropping highly correlated features in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "a750ec04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1.51761</td>\n",
       "      <td>13.89</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1.51618</td>\n",
       "      <td>13.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1.51766</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1.51742</td>\n",
       "      <td>13.27</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.24</td>\n",
       "      <td>73.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>1.51596</td>\n",
       "      <td>12.79</td>\n",
       "      <td>3.61</td>\n",
       "      <td>1.62</td>\n",
       "      <td>72.97</td>\n",
       "      <td>0.64</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>210</td>\n",
       "      <td>1.51623</td>\n",
       "      <td>14.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.88</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.08</td>\n",
       "      <td>9.18</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>211</td>\n",
       "      <td>1.51685</td>\n",
       "      <td>14.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.99</td>\n",
       "      <td>73.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.40</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>212</td>\n",
       "      <td>1.52065</td>\n",
       "      <td>14.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.02</td>\n",
       "      <td>73.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.44</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>213</td>\n",
       "      <td>1.51651</td>\n",
       "      <td>14.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.94</td>\n",
       "      <td>73.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.48</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>214</td>\n",
       "      <td>1.51711</td>\n",
       "      <td>14.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.08</td>\n",
       "      <td>73.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.62</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>213 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0        1      2     3     4      5     6     7     8     9   10\n",
       "0      2  1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.00  0.00   1\n",
       "1      3  1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.00  0.00   1\n",
       "2      4  1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.00  0.00   1\n",
       "3      5  1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.00  0.00   1\n",
       "4      6  1.51596  12.79  3.61  1.62  72.97  0.64  8.07  0.00  0.26   1\n",
       "..   ...      ...    ...   ...   ...    ...   ...   ...   ...   ...  ..\n",
       "208  210  1.51623  14.14  0.00  2.88  72.61  0.08  9.18  1.06  0.00   7\n",
       "209  211  1.51685  14.92  0.00  1.99  73.06  0.00  8.40  1.59  0.00   7\n",
       "210  212  1.52065  14.36  0.00  2.02  73.42  0.00  8.44  1.64  0.00   7\n",
       "211  213  1.51651  14.38  0.00  1.94  73.61  0.00  8.48  1.57  0.00   7\n",
       "212  214  1.51711  14.23  0.00  2.08  73.36  0.00  8.62  1.67  0.00   7\n",
       "\n",
       "[213 rows x 11 columns]"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(df[colToDrop], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4160ed",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526dd27e",
   "metadata": {},
   "source": [
    "## Node class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "94a33958",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self, featureIndex=None, threshold=None, left=None, right=None, varInformationGain=None, value=None):\n",
    "        \n",
    "        # initializing values for decision node\n",
    "        self.featureIndex = featureIndex\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.varInformationGain = varInformationGain\n",
    "        \n",
    "        # initializing values for leaf node\n",
    "        self.value = value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a87805a",
   "metadata": {},
   "source": [
    "## Tree class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "95ca17ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier():\n",
    "    def __init__(self, minSampleSplit=2, maximumDepth=2):\n",
    "        \n",
    "        # initialize the root of the tree \n",
    "        self.root = None\n",
    "        \n",
    "        #stopping conditions\n",
    "        self.minSampleSplit = minSampleSplit\n",
    "        self.maximumDepth = maximumDepth\n",
    "        \n",
    "    def generateTree(self, dataset, currentDepth=0): ###Recursive function to generate the tree\n",
    "        \n",
    "        X = dataset[:,:-1]\n",
    "        Y = dataset[:,-1]\n",
    "        totalSamples, totalFeatures = np.shape(X)\n",
    "        \n",
    "        # split until stopping conditions are met\n",
    "        if totalSamples>=self.minSampleSplit and currentDepth<=self.maximumDepth:\n",
    "            # find the most optimal split\n",
    "            optimalSplit = self.getOptimalSplit(dataset, totalSamples, totalFeatures,metrics)\n",
    "            # check if information gain is positive\n",
    "            if optimalSplit[\"varInformationGain\"]>0:\n",
    "                # recur left\n",
    "                leftSubtree = self.generateTree(optimalSplit[\"leftDataset\"], currentDepth+1)\n",
    "                # recur right\n",
    "                rightSubtree = self.generateTree(optimalSplit[\"rightDataset\"], currentDepth+1)\n",
    "                # return decision node\n",
    "                return Node(optimalSplit[\"featureIndex\"], optimalSplit[\"threshold\"], \n",
    "                            leftSubtree, rightSubtree, optimalSplit[\"varInformationGain\"])\n",
    "        \n",
    "        # compute leaf node\n",
    "        leafValue = self.calculateLeafValue(Y)\n",
    "        # return leaf node\n",
    "        return Node(value=leafValue)\n",
    "    \n",
    "    def getOptimalSplit(self, dataset, totalSamples, totalFeatures, metrics): ###function to find the optimal split\n",
    "        \n",
    "        # dictionary to store the optimal split\n",
    "        optimalSplit = {}\n",
    "        maximumInfoGain = -float(\"inf\")\n",
    "        \n",
    "        # loop over the features\n",
    "        for featureIndex in range(totalFeatures):\n",
    "            featureValues = dataset[:, featureIndex]\n",
    "            possible_thresholds = np.unique(featureValues)\n",
    "            # loop over the feature values present in the dataset\n",
    "            for threshold in possible_thresholds:\n",
    "                # get current split\n",
    "                leftDataset, rightDataset = self.split(dataset, featureIndex, threshold)\n",
    "                # check if childs are not null\n",
    "                if len(leftDataset)>0 and len(rightDataset)>0:\n",
    "                    y, leftOfY, rightOfY = dataset[:, -1], leftDataset[:, -1], rightDataset[:, -1]\n",
    "                    # calculate information gain\n",
    "                    currentInfoGain = self.informationGain(y, leftOfY, rightOfY, metrics)\n",
    "                    # update the optimal split if needed\n",
    "                    if currentInfoGain>maximumInfoGain:\n",
    "                        optimalSplit[\"featureIndex\"] = featureIndex\n",
    "                        optimalSplit[\"threshold\"] = threshold\n",
    "                        optimalSplit[\"leftDataset\"] = leftDataset\n",
    "                        optimalSplit[\"rightDataset\"] = rightDataset\n",
    "                        optimalSplit[\"varInformationGain\"] = currentInfoGain\n",
    "                        maximumInfoGain = currentInfoGain\n",
    "                        \n",
    "        # return optimal split\n",
    "        return optimalSplit\n",
    "    \n",
    "    def split(self, dataset, featureIndex, threshold): ###function to split the data \n",
    "        leftData=[]\n",
    "        rightData=[]\n",
    "        for row in dataset:\n",
    "            if(row[featureIndex]<=threshold):\n",
    "                leftData.append(row)\n",
    "            else:\n",
    "                rightData.append(row)\n",
    "        leftDataset = np.array(leftData)\n",
    "        rightDataset = np.array(rightData)\n",
    "        return leftDataset, rightDataset\n",
    "    \n",
    "    def informationGain(self, parent, leftChild, rightChild, metrics):   ###function to compute information gain\n",
    "        \n",
    "        weightOfLeft = len(leftChild) / len(parent)\n",
    "        weightOfRight = len(rightChild) / len(parent)\n",
    "        if metrics==\"gini\": ##using gini index\n",
    "            gain = self.giniIndex(parent) - (weightOfLeft*self.giniIndex(leftChild) + weightOfRight*self.giniIndex(rightChild))\n",
    "        elif metrics==\"entropy\": ##using entropy\n",
    "            gain = self.entropy(parent) - (weightOfLeft*self.entropy(leftChild) + weightOfRight*self.entropy(rightChild))\n",
    "        else: ##using gain ratio\n",
    "            gain = self.gainRatio(parent) - (weightOfLeft*self.gainRatio(leftChild) + weightOfRight*self.gainRatio(rightChild))\n",
    "        return gain\n",
    "    \n",
    "    def giniIndex(self, y):  ###function to compute gini index\n",
    "        \n",
    "        classLabels = np.unique(y)\n",
    "        gini = 0\n",
    "        for cls in classLabels:\n",
    "            probablityOfClass = len(y[y == cls]) / len(y)\n",
    "            gini += probablityOfClass**2\n",
    "        return 1 - gini\n",
    "    \n",
    "    def entropy(self, y):  ###function to compute entropy \n",
    "        \n",
    "        classLabels = np.unique(y)\n",
    "        entropy = 0\n",
    "        for cls in classLabels:\n",
    "            probablityOfClass = len(y[y == cls]) / len(y)\n",
    "            entropy += -probablityOfClass * np.log2(probablityOfClass)\n",
    "        return entropy\n",
    "    \n",
    "    def gainRatio(self, y):  ###function to compute gain ratio \n",
    "        classLabels = np.unique(y)\n",
    "        gain = 0\n",
    "        for cls in classLabels:\n",
    "            probablityOfClass = len(y[y == cls]) / len(y)\n",
    "            gain += -probablityOfClass * np.log2(probablityOfClass)\n",
    "        gain = gain / 2 ##binary classification\n",
    "        return gain\n",
    "        \n",
    "    def calculateLeafValue(self, Y):  ###function to compute leaf node \n",
    "        \n",
    "        Y = list(Y)\n",
    "        return max(Y, key=Y.count)\n",
    "    \n",
    "    def printTree(self, tree=None, indent=\" \"):        ###function to print the tree\n",
    "        \n",
    "        if not tree:\n",
    "            tree = self.root\n",
    "\n",
    "        if tree.value is not None:\n",
    "            print(tree.value)\n",
    "\n",
    "        else:\n",
    "            print(\"X_\"+str(tree.featureIndex), \"<=\", tree.threshold, \"?\", tree.varInformationGain)\n",
    "            print(\"%sleft:\" % (indent), end=\"\")\n",
    "            self.printTree(tree.left, indent + indent)\n",
    "            print(\"%sright:\" % (indent), end=\"\")\n",
    "            self.printTree(tree.right, indent + indent)\n",
    "            \n",
    "    def fit(self, X, Y, metrics): ###function to train the tree \n",
    "        \n",
    "        dataset = np.concatenate((X, Y), axis=1)\n",
    "        self.root = self.generateTree(dataset)\n",
    "    \n",
    "    def predict(self, X):  ###function to predict new dataset \n",
    "        \n",
    "        preditions = [self.makePrediction(x, self.root) for x in X]\n",
    "        return preditions\n",
    "    \n",
    "    def makePrediction(self, x, tree):  ###function to predict a single data point\n",
    "        \n",
    "        if tree.value!=None: return tree.value\n",
    "        featureValues = x[tree.featureIndex]\n",
    "        if featureValues<=tree.threshold:\n",
    "            return self.makePrediction(x, tree.left)\n",
    "        else:\n",
    "            return self.makePrediction(x, tree.right)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bd266c",
   "metadata": {},
   "source": [
    "## Train-Test Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "2571b14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1].values\n",
    "Y = df.iloc[:, -1].values.reshape(-1,1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "XTrain, XTest, YTrain, YTest = train_test_split(X, Y, test_size=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36452af",
   "metadata": {},
   "source": [
    "## Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "19e15cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=time.time()\n",
    "tracemalloc.start()\n",
    "classifier = DecisionTreeClassifier(minSampleSplit=3, maximumDepth=3)\n",
    "metrics=\"gini\"\n",
    "classifier.fit(XTrain,YTrain,metrics)\n",
    "end=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "880ed1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_0 <= 68.0 ? 0.2786332179930795\n",
      " left:1.0\n",
      " right:X_0 <= 146.0 ? 0.3228289473684211\n",
      "  left:2.0\n",
      "  right:X_0 <= 184.0 ? 0.32905229581129863\n",
      "    left:X_0 <= 163.0 ? 0.3694359866608669\n",
      "        left:3.0\n",
      "        right:5.0\n",
      "    right:7.0\n"
     ]
    }
   ],
   "source": [
    "classifier.printTree()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4d0ea3",
   "metadata": {},
   "source": [
    "## Test the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "466eb0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the classifier by using gini as an ASM is:  93.02325581395348\n",
      "Precision of the classifier by using gini as an ASM is:  78.33333333333333\n",
      "Recall score of the classifier by using gini as an ASM is:  81.57894736842107\n",
      "F1 score of the classifier by using gini as an ASM is:  79.7017797017797\n",
      "Accuracy score of the classifier by using SVM is:  93.02325581395348\n",
      "Precision of the classifier by using SVM is:  78.33333333333333\n",
      "Recall score of the classifier by using SVM is:  81.57894736842107\n",
      "F1 score of the classifier by using SVM is:  79.7017797017797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\villu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\villu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\villu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "YPredicted = classifier.predict(XTest) \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import svm\n",
    "\n",
    "print(\"Accuracy score of the classifier by using\",metrics,\"as an ASM is: \",accuracy_score(YTest, YPredicted)*100)  \n",
    "print(\"Precision of the classifier by using\",metrics,\"as an ASM is: \",precision_score(YTest, YPredicted,average='macro')*100)\n",
    "print(\"Recall score of the classifier by using\",metrics,\"as an ASM is: \",recall_score(YTest, YPredicted,average='macro')*100)\n",
    "print(\"F1 score of the classifier by using\",metrics,\"as an ASM is: \",f1_score(YTest, YPredicted,average='macro')*100)\n",
    "\n",
    "#Create a svm Classifier\n",
    "from sklearn import svm\n",
    "svmClassifier = svm.SVC(kernel='linear') # Linear Kernel\n",
    "clf.fit(XTrain, YTrain)\n",
    "y_pred = clf.predict(XTest)\n",
    "YPredicted = classifier.predict(XTest) \n",
    "print(\"Accuracy score of the classifier by using SVM is: \",accuracy_score(YTest, YPredicted)*100)  \n",
    "print(\"Precision of the classifier by using SVM is: \",precision_score(YTest, YPredicted,average='macro')*100)\n",
    "print(\"Recall score of the classifier by using SVM is: \",recall_score(YTest, YPredicted,average='macro')*100)\n",
    "print(\"F1 score of the classifier by using SVM is: \",f1_score(YTest, YPredicted,average='macro')*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "5b1cb88c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17,  2,  0,  0,  0,  0],\n",
       "       [ 0, 13,  0,  0,  0,  0],\n",
       "       [ 0,  0,  3,  0,  0,  0],\n",
       "       [ 0,  0,  0,  2,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  1],\n",
       "       [ 0,  0,  0,  0,  0,  5]], dtype=int64)"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(YTest,YPredicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "31709567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time of execution of above program is : 1273.653268814087 ms\n"
     ]
    }
   ],
   "source": [
    "print(\"The time of execution of above program is :\",\n",
    "      (end-start) * 10**3, \"ms\")\n",
    "memory=tracemalloc.get_traced_memory()\n",
    "tracemalloc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "d81032fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current memory usage  68443 KB\n",
      "Peak memory usage  155667 KB\n"
     ]
    }
   ],
   "source": [
    "print(\"Current memory usage \",memory[0],\"KB\")\n",
    "print(\"Peak memory usage \",memory[1],\"KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc68d46a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fe68b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d66d75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0cc602",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1de22b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
